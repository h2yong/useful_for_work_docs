# 性能测试指标

## Vuser 虚拟用户
Virtual user，模拟真实业务逻辑步骤的虚拟用户，虚拟用户模拟的操作步骤都被记录在虚拟用户脚本里。Vuser 脚本用于描述 Vuser 在场景中执行的操作。

## Transaction 事务
事务是性能测试脚本的一个重要特性。要度量服务器的性能，需要定义事务，每个事务都包含事务开始和事务结束标记。事务用来衡量脚本中一行代码或多行代码的执行所耗费的时间。可以将事务开始放置在脚本中某行或者多行代码的前面，将事务结束放置在该行或者多行代码的后面，在该脚本的虚拟用户运行时，这个事务将衡量该行或者多行代码的执行花费了多长时间。

## TPS 每秒事务数
(Transaction Per Second)每秒钟系统能够处理的交易或事务的数量，它是衡量系统处理能力的重要指标。TPS 是 LoadRunner 中重要的性能参数指标。

## PV（Page View）
PV 是 Page View 的缩写。用户通过浏览器访问页面，对应用服务器产生的每一次请求，记为一个 PV。大部分性能测试环境下，将这个概念做了延伸，系统真实处理的一个请求，视为一个 PV。即，PV 的概念也适用于接口。

## Peak PV 高峰 Page View
即 PV 峰值，指一天中 PV 数达到的最高峰。

## Concurrency并发
并发分为狭义和广义两类。
狭义的并发，即所有的用户在同一时刻做同一件事情或操作，这种操作一般针对同一类型的业务；或者所有用户进行完全一样的操作，目的是测试数据库和程序对并发操作的处理。  
广义的并发，即多个用户对系统发出了请求或者进行了操作，但是这些请求或操作可以是不同的。对整个系统而言，仍然有很多用户同时进行操作。  
狭义并发强调对系统的请求操作是完全相同的，多适用于性能测试、负载测试、压力测试、稳定性测试场景；广义并发不限制对系统的请求操作，多适用于混合场景、稳定性测试场景。

## 吞吐量
吞吐量为“单位时间内系统处理的客户请求的数量”，直接体现软件系统的性能承载能力，对于交互式应用系统来说、吞吐量反映的是服务器承受的压力、在容量规划的测试中、吞吐量是一个重要指标、它不但反映在中间件、数据库上、更加体现在硬件上。我们在以下方面利用这个指标：

1. 用来协助设计软件性能测试场景，衡量软件性能测试是否达到了预计的设计目标、比如J2EE应用系统的连接池、数据库事务发生频率、事务发生次数。  
2. 用来协助分析性能瓶颈

## Scenario 场景
性能测试过程中为了模拟真实用户的业务处理过程，在 Loadrunner 中构建的基于事务、脚本、虚拟用户、运行设置、运行计划、监控、分析等的一系列动作的集合，称之为性能测试场景。场景中包含了待执行脚本、脚本组、并发用户数、负载生成器、测试目标、测试执行时的配置条件等。

## Response Time 响应时间
响应时间是指从客户端发一个请求开始计时，到客户端接收到从服务器端返回的响应结果结束所经历的时间，响应时间由请求发送时间、网络传输时间和服务器处理时间三部分组成。

## Think Time 思考时间
模拟正式用户在实际操作时的停顿间隔时间。
从业务的角度来讲，思考时间指的是用户在进行操作时，每个请求之间的间隔时间。
在测试脚本中，思考时间体现为脚本中两个请求语句之间的间隔时间。

## CPU 资源
CPU 资源是指性能测试场景运行的这个时间段内，应用服务系统的 CPU 资源占用率。CPU 资源是判断系统处理能力以及应用运行是否稳定的重要参数。应用系统可以包括应用服务器、web 服务器、数据库服务器等。

## Load 负载
系统平均负载，被定义为在特定时间间隔内运行队列中的平均进程数。如果一个进程满足以下条件则其就会位于运行队列中：

- 它没有在等待 I/O 操作的结果
- 它没有主动进入等待状态（也就是没有调用'wait'）
- 没有被停止（例如：等待终止）

## Std. Deviation 标准差
该标准差根据数理统计的概念得来，标准差越小，说明波动越小，系统越稳定，反之，标准差越大，说明波动越大，系统越不稳定。包括响应时间标准差和 TPS 标准差等。

# 性能测试策略
性能测试确立了成型的整套策略，从性能测试环境，到性能测试数据、执行、调优、性能评估，都已经摸索出操作性很强的策略。具体策略如下：

1. 模拟生产线真实的硬件环境。
2. 服务器置于同一机房，最大限度避免网络问题。
3. 以 PV 为切入点，通过模型将其转换成性能测试可量化的 TPS。
4. 性能测试数据分为基础数据和业务数据两部分，索引和 SQL 都会被测试到。
5. 先单场景，后混合场景，确保每个性能瓶颈都得到调优。
6. 拆分问题，隔离分析，定位性能瓶颈。
7. 根据性能测试通过标准，来判断被测性能点通过与否。
8. 针对当前无法解决的性能瓶颈，录入 QC 域进行跟踪，并请专家进行风险评估。

# 性能测试类型

## 性能测试
定义：狭义的性能测试，是指以性能预期目标为前提，对系统不断施加压力，验证系统在资源可接受范围内，是否能达到性能预期。

## 负载测试
定义：狭义的负载测试，是指对系统不断地增加压力或增加一定压力下的持续时间，直到系统的某项或多项性能指标达到极限，例如某种资源已经达到饱和状态等。

## 压力测试
定义：狭义的压力测试，是指超过安全负载的情况下，对系统不断施加压力，是通过确定一个系统的瓶颈或不能接收用户请求的性能点，来获得系统能提供的最大服务级别的测试。

## 稳定性测试
定义：狭义的稳定性测试，是指被测试系统在特定硬件、软件、网络环境条件下，给系统加载一定业务压力，使系统运行一段较长时间，以此检测系统是否稳定，一般稳定性测试时间为 n\*12 小时。

# 性能测试执行方法
性能测试通常采用先单场景，后混合场景的执行方法。

## 单场景
针对单个性能测试点，构建一个性能测试场景，而进行的性能测试。单场景适用于性能测试、负载测试、压力测试、稳定性测试。

## 混合场景
为了尽量模拟生产线上运行的业务压力或用户使用场景，测试系统的整体性能是否满足性能需求，把经过一定规则筛选的性能测试点，按照合乎实际逻辑的虚拟用户请求、并发，组合成一个混合场景。
混合场景的特征，通常包含两个或者两个以上的脚本组，执行时间较长。混合场景通常在稳定性测试、负载测试中使用。

# 性能监控
性能测试需要使用不同的工具，结合系统日志，监控服务器、应用等方面的多项指标。以下阐述监控指标、监控工具和监控步骤。

## 监控指标
性能测试通常需要监控的指标包括：

1. 服务器 Linux（包括 CPU、Memory、Load、I/O）。
2. 数据库：1.Mysql 2.Oracle（缓存命中、索引、单条 SQL 性能、数据库线程数、数据池连接数）。
3. 中间件：1.Jboss 2. Apache（包括线程数、连接数、日志）。
4. 网络： 吞吐量、吞吐率。
5. 应用： jvm 内存、日志、Full GC 频率。
6. 监控工具（LoadRunner）：用户执行情况、场景状态、事务响应时间、TPS 等。
7. 测试机资源：CPU、Memory、网络、磁盘空间。

## 监控工具
性能测试通常采用下列工具进行监控：

1. Profiler  
   一个记录 log 的类，阿里巴巴集团自主开发，嵌入到应用代码中使用。
2. Jstat  
   监控 java 进程 GC 情况，判断 GC 是否正常。
3. JConsole  
   监控 java 内存、java CPU 使用率、线程执行情况等，需要在 JVM 参数中进行配置。
4. JMap  
   监控 java 程序是否有内存泄漏，需要配合 eclipse 插件或者 MemoryAnalyzer 来使用。
5. JProfiler  
   全面监控每个节点的 CPU 使用率、内存使用率、响应时间累计值、线程执行情况等，需要在 JVM 参数中进行配置。
6. nmon  
   全面监控 linux 系统资源使用情况，包括 CPU、内存、I/O 等，可独立于应用监控。
7. valgrind  
   监控 C/C++程序是否存在内存泄漏，基于 linux 环境。
8. Vmmap 和 ApplicationVerifier  
   监控 C/C++程序是否存在内存泄漏，基于 windows 环境。

## 监控步骤
1. 确定需要监控的目标。
2. 确定监控和分析所需信息（可以采用 CheckList 模版法，列出所需要监控的指标，信息）。
3. 确定监控所使用的工具（根据性能点的类型，以及需要关注的性能指标来确定）。
4. 收集监控所得数据（可以采用日志监控＋辅助工具法，收集所需监控数据）。
5. 分析所采集的数据，定位性能瓶颈。
6. 性能调优。
7. 循环以上步骤，直到调优完毕。

# 性能分析
## 分析原则

在分布式架构下，性能瓶颈分析也变得相对困难。根据不同的应用系统，不同的测试目标，不同的性能关注点，根据性能指标的表现，采用“拆分问题，隔离分析”的方法进行分析，即逐步定位、从外到内、从表及里、逐层分解、隔离排除。

具体可按以下顺序：

中间件瓶颈（apache/jboss 参数配置、数据库参数配置）-> 应用服务的 debug log -> 应用服务的 filter log -> 本应用的性能瓶颈（SQL 语句、索引、业务逻辑、线程池设置、算法）-> 服务提供者的性能瓶颈 -> 相关联的底层存储应用的性能瓶颈

注：以上是比较通用的分析过程，具体性能测试查找瓶颈过程中，需要具体问题具体分析。

## 分析信息来源
1. 监控工具所采集的信息。包括 TPS、响应时间、用户并发数、JVM 内存、Full GC 频率等。
2. 应用服务器的日志。包括错误日志、超时日志等。
3. 项目配合人员所提供的信息。包括 DBA 提供的数据库监控信息、开发人员提供的代码逻辑信息。

## 分析标准
通过性能指标的表现形式，分析性能是否稳定。比如：

1. 响应时间是否符合性能预期，表现是否稳定。
2. 应用日志中，超时的概率，是否在可接受的范围之内。
3. TPS 维持在多大的范围内，是否有波形出现，标准差有多少，是否符合预期。
4. 服务器 CPU、内存、load 是否在合理的范围内，等等。

## 分析工具
对于部分性能指标，可借助自动分析工具，统计出数据的总体趋势：

1. LoadRunner analysis 分析  
   LoadRunner analysis 是 loadrunner 的一个部件，用于将运行过程中所采集到的数据生成报表，主要用于采集 TPS、响应时间、服务器资源使用情况等变化趋势。

2. Memory Analyzer 分析  
   Memory Analyzer 工具可以解析 Jmap dump 出来的内存信息，查找是否有内存泄漏。

3. nmon_analyser 分析  
   nmon 工具可以采集服务器的资源信息。列出 CPU、MEM、网络、I/O 等资源指标的使用情况。

# 性能测试通过标准

性能测试通过标准包括服务端性能、前端性能和用户体验性能，通过标准参考下表：

| 类别         | 判断维度       | 标准                         |
| ------------ | -------------- | ---------------------------- |
| 服务器端性能 | 超时概率       | 小于万分之一                 |
| 服务器端性能 | 错误概率       | 小于万分之一                 |
| 服务器端性能 | TPS            | 大于期望高峰值               |
| 服务器端性能 | CPU 利用率     | 小于 75%                     |
| 服务器端性能 | Load           | 平均每核 CPU 的 Load 小于 1  |
| 服务器端性能 | JVM 内存使用率 | 小于 80%                     |
| 服务器端性能 | fullGC 频率    | 平均大于半小时一次           |
| 前端性能     | YSlow 评定     | YSlow 评定为 C 级或 C 级以上 |

# 参考

- 淘宝性能测试白皮书
